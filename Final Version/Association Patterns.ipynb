# Import libraries

import nltk
import re
import os
import time
from nltk.tokenize import sent_tokenize
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules
import mlxtend as ml
import pandas as pd
import numpy as np
from mlxtend.preprocessing import TransactionEncoder
from wordcloud import WordCloud
import matplotlib
import matplotlib.pyplot as plt
import warnings
from collections import OrderedDict
sentdetector = nltk.data.load('tokenizers/punkt/english.pickle')
# Regex for family members

familynames = re.compile(r'\b(mother|brother|grandfather|sister|grandmother|father|mom|dad|son|daughter|uncle|aunt|niece|nephew|cousin)(\'s|s)*\b', re.I)

# Read the txt files containing medical transcripts

def read_text_file(file_path):
    
    familysentences =[]
    text = open(file_path, encoding="utf8", errors='ignore').read()
    
    # tokenize the sentences     
    sentences = sentdetector.tokenize(text.strip(), realign_boundaries=True)
    
    # Get only those sentences with family members and 
    # remove white space characters, numbers and special symbols    
    for sent in sentences:
        if familynames.search(sent) is not None:
            sent = re.sub(r"[\n\t]*", "", sent)
            sent = re.sub(r'[^\w\s]', '', sent)
            sent = re.sub(r'[\d+]', '', sent)
            familysentences.append(sent.lower())

    return familysentences    
# Remove stop words from the tokenized sentences

def remove_stop_words(token_data):
    filtered_sentences = []
    for sentence in token_data:
        stop_words = set(stopwords.words('english'))
        word_tokens = word_tokenize(sentence)
        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]
        filtered_sentence = []
    
        for w in word_tokens:
            if w not in stop_words:
                filtered_sentence.append(w)
                
        filtered_sentences.append(filtered_sentence)
    return filtered_sentences

# 3.1 and 3.2

# Get path. My file path is currently set. 

path = os.getcwd()
# os.chdir('./data')
# print(path)


files = []
token_data = []
filtered_data = []

for file in os.listdir():
    # Check whether file is in text format or not
    if file.endswith(".txt"):
        file_path = f"{path}//{file}"

        # Read the text file data        
        file_data = read_text_file(file_path)
        new = ' '.join(file_data)

        if (len(file_data) != 0):
            token_data.append(new)

# Remove stop words from the data read from text file
filtered_data = remove_stop_words(token_data)
print(len(filtered_data), filtered_data)
    
# 3.3

# Calculate minimum threshold. Since we want to have identify all the word associations 
# that occur in at least 5 sentences. 

min_support_threshold = round((5/len(filtered_data)), 2)
print(min_support_threshold)

# Convert data into dataframes, with the words as columns. 

te = TransactionEncoder()
te_ary = te.fit(filtered_data).transform(filtered_data)
df = pd.DataFrame(te_ary, columns=te.columns_)
df
# Using mlxtend, apply the apriori function

itemsets = apriori(df, min_support= min_support_threshold, use_colnames=True)
# Get the association rules. 

rules = association_rules(itemsets, metric='lift', min_threshold=0.5)
# Sort the rules in descending order of lift. 

rules.sort_values("lift", ascending = False, inplace = True)
rules
rules.shape
# Visualizing the results: 

# Support vs Confidence

plt.scatter(rules['support'], rules['confidence'], alpha=0.5)
plt.xlabel('support')
plt.ylabel('confidence')
plt.title('Support vs Confidence')
plt.show()
# Support vs Lift 

plt.scatter(rules['support'], rules['lift'], alpha=0.5)
plt.xlabel('support')
plt.ylabel('lift')
plt.title('Support vs Lift')
plt.show()
# Lift vs Confidence

fit = np.polyfit(rules['lift'], rules['confidence'], 1)
fit_fn = np.poly1d(fit)
plt.plot(rules['lift'], rules['confidence'], 'yo', rules['lift'], 
 fit_fn(rules['lift']))
plt.title('Lift vs Confidence')

# Filter the rules with respect to lift and confidence.

rec_rules = rules[ (rules['lift'] > 1) & (rules['confidence'] >= 0.5) ]
# Remove columns that are not needed, like antecedent support, consequent support, leverage and conviction.

cols_keep = {'antecedents':'item_1', 'consequents':'item_2', 'support':'support', 'confidence':'confidence', 'lift':'lift'}
cols_drop = ['antecedent support', 'consequent support', 'leverage', 'conviction']

word_associations = pd.DataFrame(rec_rules).rename(columns= cols_keep).drop(columns=cols_drop).sort_values(by=['support'], ascending = False)

display(word_associations)

# Get antecedents and consequents as a list
antecedents = []
antecedents_list = []
for i in word_associations['item_1']:
    antecedents.append(list(i))
    antecedents_list.append(' '.join(i))

consequents = []
consequents_list = []
for i in word_associations['item_2']:
    consequents.append(list(i))
    consequents_list.append(' '.join(i))
# Getting a visual understanding of the data using wordcloud

warnings.filterwarnings("ignore", category=DeprecationWarning) 
stop = ['history', 'family', 'died', 'one', 'two', 'age']
stopwords = set(stop)

def wordcloud(df, item_list):
    wordcloud_ent = WordCloud(width = 800, height = 500,
                background_color ='black',
                stopwords = stopwords,
                min_font_size = 10).generate(' '.join(item_list))
    plt.imshow(wordcloud_ent, interpolation='bilinear')
    plt.axis("off")
    return plt.show()

# Wordcloud for antecedents

wordcloud(df, antecedents_list)
# Wordcloud for consequents

wordcloud(df, consequents_list)
# 3.4 

# Getting indexes of the antecedents and consequents from token data.

index_dict = {}
c_index_list = []
a_index_list = []

for sentence in range(len(token_data)):
    for i in antecedents:
        try:
            a_index = token_data[sentence].index(i[0])  
        except ValueError:
            a_index = -1
        a_index_list.append(a_index)
    for j in consequents:
        try:
            c_index = token_data[sentence].index(i[len(i)-1])
        except ValueError:
            c_index = -1
        c_index_list.append(c_index)

# Get the span from the user.

input_k = int(input("Enter k value between 5,7 or 10 "))
print(input_k)
# Calculate the sentence span.

index_dict = {}
less_than_dict = {}

time1 = time.time()

for a in range(len(antecedents)):
    for i in range(len(token_data)):
        split_word = token_data[i].split()
        if ((antecedents[a][0] in token_data[i]) and (consequents[a][len(consequents[a])-1] in token_data[i]))!= False:
            
            a_index = -1
            c_index = -1
            
            # Get index of the antecedents and consequents in the actual sentences            
            for k, j in enumerate(token_data[i].split()):
                if (j == antecedents[a][0]):
                    a_index = k+1
                    break
            for k, j in enumerate(token_data[i].split()):
                if (j == consequents[a][len(consequents[a])-1]):
                    c_index = k+1
                    break
            
            # Check if the span is more than input. 
            if c_index >= 0 and a_index >= 0 and (c_index - a_index) > input_k:
                key = tuple([antecedents[a][0], consequents[a][len(consequents[a])-1]])
                if key in index_dict:
                    index_dict[key] += 1
                else:
                    index_dict[key] = 1
            elif c_index >= 0 and a_index >= 0 and (c_index - a_index) <= input_k:
                key = tuple([antecedents[a][0], consequents[a][len(consequents[a])-1]])
                if key in less_than_dict:
                    less_than_dict[key] += 1
                else:
                    less_than_dict[key] = 1
                
time2 = time.time()
print("Time taken = ", (time2-time1))
print(len(less_than_dict), less_than_dict)
                
# Remove the sentences that have span more than k and frequency more than 60%.

sixty_percent = round((60 * len(token_data))/100)

new_dict = {}
less_dict = {}

for combination in index_dict:
    # Tokens to be removed
    if index_dict[combination] >= sixty_percent:
        new_dict[combination] = index_dict[combination]
    # Tokens to be kept
    else:
        less_dict[combination] = index_dict[combination]

print(len(new_dict), new_dict)
print("------------------------")
print(len(less_dict), less_dict)
    
# Creating a main list of all correct association patterns.

main_dict = {}
main_dict = less_than_dict.copy()

for key in less_dict:
    if key in main_dict:
        main_dict[key] += less_dict[key]
    else:
        main_dict[key] = less_dict[key]
        
print(len(main_dict), main_dict)

# 3.5 

# Check for relative arrangement of the association patterns.

wordList = []
wordListDict = {}
dict_keys = list(main_dict.keys())

for words in dict_keys:
    for a in dict_keys:
        if ([str(words[1]), str(words[0])] == list(a)):
            key = words
            if not ((words in wordListDict) or (a in wordListDict)):
                wordListDict[key] = int(main_dict[key])
                wordListDict[key] += int(main_dict[a])
            wordList.append(words)
            
print(len(wordListDict), sorted(wordList))



# 3.6 

# Ordering the list by its frequency

dictionary_keys = list(wordListDict.keys())
sorted_dict = {dictionary_keys[i]: sorted(
    wordListDict.values())[i] for i in range(len(dictionary_keys))}

print(sorted_dict)
# List of family members

family = ["mother", "mothers", "brother", "brothers", "grandfather", "grandfathers", "sister", "sisters", "grandmother", "grandmothers", "father", "fathers", "mom", "moms", "dad", "dads", "son", "sons", "daughter", "daughters", "uncle", "uncles", "aunt", "aunts", "niece", "nieces", "nephew", "nephews", "cousin", "cousins"]

# 3.6 (a)
# WordList that contains atleast one family member.

family_list = []
keys_list = list(wordListDict.keys())
for key in keys_list:
    for member in family:
        if member in key:
            family_list.append(key)
            
print(len(family_list), family_list)
# List of diseases

diseases = ["breast", "cancer", "ADHD", "HTN", "bipolar", "hypertension", "CA", "bipolar", "brain aneurysm", "cancer", "depressed","cerebral", "aneurysm", "colon", "depression","cerebrovascular", "accident","gastric", "carcinoma","mental", "illness", "stroke","lung" ,"mood", "disorder", "strokes","prostate" ,"adult-onset", "diabetes","renal" "CA","nervous", "breakdowns", "throat", "Schizophrenia", "mellitus", "CHF", "suicide", "DM", "CAD","coronary", "heart", "disease","type", "coronary"  ,"acute", "myocardial", "infarction", "attack","alcohol", "abuse","congestive", "failure", "alcoholic","artery" , "alcoholism",  "valvular", "MI",  "use","vascular" ,"drug", "addict", "substance" ]

# 3.6 (b)
# WordList that contains atleast one disease.

disease_list = []
for key in keys_list:
    for member in diseases:
        if member in key:
            disease_list.append(key)
print(len(disease_list), disease_list)
# Function to check if disease is present

def isDiseasePresent(key):
    isPresent = False
    for disease in diseases:
        if disease in key:
            isPresent = True
            break
        else:
            isPresent = False
    return isPresent
# Function to check if family member is present

def isFamilyPresent(key):
    isPresent = False
    for member in family:
        if member in key:
            isPresent = True
            break
        else:
            isPresent = False
    return isPresent
# 3.6 (c)
# WordList that contains atleast one family member but no disease.

familyNoDisease = []
keys_list = list(wordListDict.keys())

for key in keys_list:
    for member in family:
        isPresent = isDiseasePresent(key)
        if member in key and (not isPresent):
            familyNoDisease.append(key)

print(len(familyNoDisease), familyNoDisease)
            

# 3.6 (d)
# WordList that contains both a family member and a disease.

familyDisease = []
keys_list = list(wordListDict.keys())

for key in keys_list:
    for member in family:
        isPresent = isDiseasePresent(key)
        if member in key:
            for disease in diseases:
                if disease in key:
                    familyDisease.append(key)

print(len(familyDisease), familyDisease)
            

# 3.6 (e)
# WordList that contains neither a family nor a disease.
noFamilyNoDisease = []
keys_list = list(wordListDict.keys())

for key in keys_list:
    if (not isDiseasePresent(key)) and (not isFamilyPresent(key)):
        noFamilyNoDisease.append(key)
        
print(len(noFamilyNoDisease), noFamilyNoDisease)

# 3.6 (g) 
# Common characteristics observed in its top 20 frequent wordLists

# Mother seems to be the most frequent in all the family members. 
# Followed by father, brother and sister .
# Least common family member seem to be grandmother, son and daughter.

# This means that most of the diseases seem to be inherited from mother and father. 

# Check wordLists containing mother 

family_list = []
keys_list = list(wordListDict.keys())
for key in keys_list:
    if "mother" in key or "mom" in key:
        family_list.append(key)
        
print(len(family_list), family_list)
# Check wordLists containing father 

family_list = []
keys_list = list(wordListDict.keys())
for key in keys_list:
    if "father" in key or "fathers" in key:
        family_list.append(key)
        
print(len(family_list), family_list)
# 3.7 
# WordList that contains atleast one disease but no family member.

noFamilyDisease = []
keys_list = list(wordListDict.keys())

for key in keys_list:
    for member in diseases:
        isPresent = isFamilyPresent(key)
        if member in key and (not isPresent):
            noFamilyDisease.append(key)

print(len(noFamilyDisease), noFamilyDisease)
# The disease cancer seems to be most frequent, specifically breast cancer.
# Followed by heart attack, coronary heart disease, coronary artery disease
# Hypertension, congestive heart failure and diabetes (usual as well as type 2) seem to be least common

disease_list = []
keys_list = list(wordListDict.keys())
for key in keys_list:
    if "cancer" in key:
        disease_list.append(key)
        
print(len(disease_list), disease_list)
# 3.8

# IMPORTANT: The potential solution to identify family history information of a patient in the format: 
# (family member, disease). 

# (Mother, Father, Brother	Cancer)
# (Mother	Breast Cancer)
# (Mother, Father	Hypertension)
# (Father, Mother	Coronary artery disease)
# (Father, Mother	Heart attack)
# (Brother	Heart disease)
# (Father	Heart failure)
# (Mother, Father	Depression)
# (Father	Congestive heart failure)
# (Mother, Father	Alchohol abuse)
# (Mother, Grandmother	Diabetes)
# (Father	Coronary heart disease)

# From the above list, it seems that cancer is the most indicative of a heriditary nature. 
# There seems to be the maximum correlation between cancer and father, mother and brother.
# Breast cancer, especially, is related to mother. 
# Hypertension is also correlated with mother and father. 
# Diabeters seems to be more related to mother and grandmother.
# Heart diseases, coronary heart disease, coronary artery disease seem to be related to father. 
# Alchohol abuse and alchoholism along with mental illnesses seem to be inherited from mother and father. 

# Pros: There is clear correlation between aforementioned diseases and the 
#       family members mentioned. 

# Cons: The correlation can only be found for the most commonly found diseases. 
#       There isn't much data available for all the diseases to find a clear correlation. 
#       More data is needed for finding association patterns for all diseases. 


